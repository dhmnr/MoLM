{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen/Qwen2.5-Coder-7B...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43d22afc20b49389e2b4f690272ddc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1 samples per task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating solutions:   0%|          | 0/164 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   1%|          | 1/164 [00:10<29:05, 10.71s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   1%|          | 2/164 [00:15<18:58,  7.03s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   2%|▏         | 3/164 [00:37<37:09, 13.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   2%|▏         | 4/164 [00:42<28:11, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   3%|▎         | 5/164 [00:43<18:54,  7.13s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   4%|▎         | 6/164 [00:44<13:28,  5.11s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   4%|▍         | 7/164 [00:45<09:29,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   5%|▍         | 8/164 [01:07<24:46,  9.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   5%|▌         | 9/164 [01:29<34:34, 13.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   6%|▌         | 10/164 [01:51<41:06, 16.02s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   7%|▋         | 11/164 [01:52<29:15, 11.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   7%|▋         | 12/164 [02:14<37:03, 14.63s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   8%|▊         | 13/164 [02:15<26:42, 10.61s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   9%|▊         | 14/164 [02:37<35:00, 14.00s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:   9%|▉         | 15/164 [02:59<40:37, 16.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  10%|▉         | 16/164 [03:21<44:23, 17.99s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  10%|█         | 17/164 [03:43<47:01, 19.19s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  11%|█         | 18/164 [03:52<39:08, 16.08s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  12%|█▏        | 19/164 [04:14<43:17, 17.91s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  12%|█▏        | 20/164 [04:36<45:51, 19.11s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  13%|█▎        | 21/164 [04:58<47:36, 19.97s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  13%|█▎        | 22/164 [05:20<48:37, 20.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  14%|█▍        | 23/164 [05:20<34:19, 14.61s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  15%|█▍        | 24/164 [05:42<39:10, 16.79s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  15%|█▌        | 25/164 [06:04<42:26, 18.32s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  16%|█▌        | 26/164 [06:05<30:24, 13.22s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  16%|█▋        | 27/164 [06:27<36:09, 15.84s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  17%|█▋        | 28/164 [06:49<40:00, 17.65s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  18%|█▊        | 29/164 [07:11<42:36, 18.94s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  18%|█▊        | 30/164 [07:33<44:20, 19.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  19%|█▉        | 31/164 [07:55<45:26, 20.50s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  20%|█▉        | 32/164 [08:17<46:02, 20.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  20%|██        | 33/164 [08:20<33:43, 15.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  21%|██        | 34/164 [08:42<37:40, 17.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  21%|██▏       | 35/164 [09:04<40:17, 18.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  22%|██▏       | 36/164 [09:25<41:54, 19.64s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  23%|██▎       | 37/164 [09:46<42:33, 20.11s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  23%|██▎       | 38/164 [10:08<43:03, 20.51s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  24%|██▍       | 39/164 [10:29<43:17, 20.78s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  24%|██▍       | 40/164 [10:35<33:27, 16.19s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  25%|██▌       | 41/164 [10:56<36:25, 17.77s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  26%|██▌       | 42/164 [10:58<26:26, 13.00s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  26%|██▌       | 43/164 [11:20<31:20, 15.54s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  27%|██▋       | 44/164 [11:41<34:37, 17.32s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  27%|██▋       | 45/164 [12:03<36:48, 18.56s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  28%|██▊       | 46/164 [12:24<38:13, 19.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  29%|██▊       | 47/164 [12:45<39:05, 20.04s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  29%|██▉       | 48/164 [13:07<39:34, 20.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  30%|██▉       | 49/164 [13:28<39:50, 20.78s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  30%|███       | 50/164 [13:51<40:17, 21.21s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  31%|███       | 51/164 [14:13<40:34, 21.54s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  32%|███▏      | 52/164 [14:35<40:26, 21.66s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  32%|███▏      | 53/164 [14:57<40:15, 21.76s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  33%|███▎      | 54/164 [15:19<40:00, 21.82s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  34%|███▎      | 55/164 [15:20<28:11, 15.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  34%|███▍      | 56/164 [15:42<31:24, 17.45s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  35%|███▍      | 57/164 [15:43<22:35, 12.67s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  35%|███▌      | 58/164 [16:05<27:19, 15.47s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  36%|███▌      | 59/164 [16:27<30:36, 17.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  37%|███▋      | 60/164 [16:34<24:31, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  37%|███▋      | 61/164 [16:56<28:19, 16.50s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  38%|███▊      | 62/164 [17:00<21:36, 12.71s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  38%|███▊      | 63/164 [17:17<23:56, 14.22s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  39%|███▉      | 64/164 [17:39<27:36, 16.57s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  40%|███▉      | 65/164 [18:01<30:05, 18.24s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  40%|████      | 66/164 [18:06<22:50, 13.99s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  41%|████      | 67/164 [18:06<15:59,  9.89s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  41%|████▏     | 68/164 [18:11<13:20,  8.34s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  42%|████▏     | 69/164 [18:33<19:51, 12.54s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  43%|████▎     | 70/164 [18:55<24:07, 15.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  43%|████▎     | 71/164 [19:17<26:57, 17.39s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  44%|████▍     | 72/164 [19:20<19:53, 12.98s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  45%|████▍     | 73/164 [19:20<13:55,  9.18s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  45%|████▌     | 74/164 [19:24<11:16,  7.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  46%|████▋     | 76/164 [19:44<12:44,  8.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  47%|████▋     | 77/164 [19:48<10:54,  7.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  48%|████▊     | 78/164 [20:10<16:16, 11.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  48%|████▊     | 79/164 [20:15<13:30,  9.54s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  49%|████▉     | 80/164 [20:18<11:02,  7.89s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  49%|████▉     | 81/164 [20:40<16:32, 11.95s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  50%|█████     | 82/164 [21:02<20:19, 14.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  51%|█████     | 83/164 [21:24<22:51, 16.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  51%|█████     | 84/164 [21:26<16:42, 12.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  52%|█████▏    | 85/164 [21:30<13:00,  9.88s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  52%|█████▏    | 86/164 [21:52<17:29, 13.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  53%|█████▎    | 87/164 [21:52<12:17,  9.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  54%|█████▎    | 88/164 [22:14<16:48, 13.27s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  54%|█████▍    | 89/164 [22:21<14:19, 11.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  55%|█████▍    | 90/164 [22:23<10:38,  8.63s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  55%|█████▌    | 91/164 [22:45<15:22, 12.63s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  56%|█████▌    | 92/164 [23:07<18:33, 15.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  57%|█████▋    | 93/164 [23:08<13:07, 11.09s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  57%|█████▋    | 94/164 [23:10<09:38,  8.26s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  58%|█████▊    | 95/164 [23:32<14:15, 12.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  59%|█████▊    | 96/164 [23:36<11:05,  9.79s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  59%|█████▉    | 97/164 [23:58<15:01, 13.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  60%|█████▉    | 98/164 [24:02<11:45, 10.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  60%|██████    | 99/164 [24:05<09:11,  8.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  61%|██████    | 100/164 [24:06<06:32,  6.14s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  62%|██████▏   | 101/164 [24:16<07:41,  7.32s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  62%|██████▏   | 102/164 [24:20<06:34,  6.37s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  63%|██████▎   | 103/164 [24:42<11:15, 11.07s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  63%|██████▎   | 104/164 [25:04<14:21, 14.36s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  64%|██████▍   | 105/164 [25:06<10:21, 10.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  65%|██████▍   | 106/164 [25:06<07:11,  7.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  65%|██████▌   | 107/164 [25:28<11:12, 11.80s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  66%|██████▌   | 108/164 [25:28<07:44,  8.30s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  66%|██████▋   | 109/164 [25:50<11:22, 12.40s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  67%|██████▋   | 110/164 [26:12<13:46, 15.30s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  68%|██████▊   | 111/164 [26:34<15:17, 17.30s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  68%|██████▊   | 112/164 [26:56<16:11, 18.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  69%|██████▉   | 113/164 [26:57<11:18, 13.30s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  70%|██████▉   | 114/164 [27:19<13:14, 15.89s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  70%|███████   | 115/164 [27:27<11:10, 13.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  71%|███████   | 116/164 [27:49<12:56, 16.18s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  71%|███████▏  | 117/164 [27:50<09:04, 11.58s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  72%|███████▏  | 118/164 [27:56<07:28,  9.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  73%|███████▎  | 119/164 [28:18<10:04, 13.43s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  73%|███████▎  | 120/164 [28:40<11:43, 16.00s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  74%|███████▍  | 121/164 [28:40<08:04, 11.27s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  74%|███████▍  | 122/164 [29:02<10:08, 14.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  75%|███████▌  | 123/164 [29:02<07:01, 10.27s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  76%|███████▌  | 124/164 [29:06<05:32,  8.32s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  76%|███████▌  | 125/164 [29:28<08:04, 12.42s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  77%|███████▋  | 126/164 [29:29<05:43,  9.04s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  77%|███████▋  | 127/164 [29:33<04:36,  7.48s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  78%|███████▊  | 128/164 [29:55<07:07, 11.88s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  79%|███████▊  | 129/164 [30:18<08:45, 15.03s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  79%|███████▉  | 130/164 [30:18<05:58, 10.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  80%|███████▉  | 131/164 [30:27<05:32, 10.09s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  80%|████████  | 132/164 [30:49<07:20, 13.75s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  81%|████████  | 133/164 [31:11<08:26, 16.35s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  82%|████████▏ | 134/164 [31:18<06:45, 13.52s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  82%|████████▏ | 135/164 [31:28<05:57, 12.34s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  83%|████████▎ | 136/164 [31:38<05:29, 11.75s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  84%|████████▎ | 137/164 [32:01<06:42, 14.90s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  84%|████████▍ | 138/164 [32:04<04:54, 11.33s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  85%|████████▍ | 139/164 [32:06<03:39,  8.77s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  85%|████████▌ | 140/164 [32:09<02:49,  7.05s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  86%|████████▌ | 141/164 [32:13<02:17,  5.99s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  87%|████████▋ | 142/164 [32:35<03:59, 10.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  87%|████████▋ | 143/164 [32:57<04:59, 14.28s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  88%|████████▊ | 144/164 [32:59<03:31, 10.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  88%|████████▊ | 145/164 [33:21<04:26, 14.02s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  89%|████████▉ | 146/164 [33:44<04:56, 16.46s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  90%|████████▉ | 147/164 [34:16<06:00, 21.19s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  90%|█████████ | 148/164 [34:18<04:09, 15.60s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  91%|█████████ | 149/164 [34:45<04:43, 18.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  91%|█████████▏| 150/164 [34:46<03:10, 13.62s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  92%|█████████▏| 151/164 [35:13<03:48, 17.56s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  93%|█████████▎| 152/164 [35:39<04:00, 20.01s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  93%|█████████▎| 153/164 [35:39<02:35, 14.12s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  94%|█████████▍| 154/164 [35:45<01:55, 11.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  95%|█████████▍| 155/164 [35:45<01:13,  8.14s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  95%|█████████▌| 156/164 [35:47<00:51,  6.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  96%|█████████▌| 157/164 [35:52<00:41,  5.95s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  96%|█████████▋| 158/164 [35:54<00:28,  4.71s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  97%|█████████▋| 159/164 [36:20<00:55, 11.01s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  98%|█████████▊| 160/164 [36:20<00:31,  7.92s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  98%|█████████▊| 161/164 [36:23<00:18,  6.24s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  99%|█████████▉| 162/164 [36:45<00:22, 11.05s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions:  99%|█████████▉| 163/164 [36:53<00:10, 10.20s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Generating solutions: 100%|██████████| 164/164 [37:21<00:00, 13.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples saved to samples_Qwen_Qwen2.5-Coder-7B.json\n",
      "\n",
      "To evaluate, run:\n",
      "Reading samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [00:00, 38267.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test suites...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:08<00:00, 19.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing results to samples_Qwen_Qwen2.5-Coder-7B.json_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 33972.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pass@1': np.float64(0.21951219512195122)}\n"
     ]
    }
   ],
   "source": [
    "from human_eval.data import write_jsonl, read_problems\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from human_eval.evaluation import evaluate_functional_correctness\n",
    "from molm.utils.utils import extract_generation_code, languge_settings\n",
    "\n",
    "import os\n",
    "\n",
    "# def build_qwen_instruction(question: str, languge: str = 'python', ):\n",
    "#     return \"\"\"\n",
    "# Please continue to complete the function. You are not allowed to modify the given code and do the completion only. Please return all completed function in a codeblock. Here is the given code to do completion:\n",
    "# ```{}\n",
    "# {}\n",
    "# ```\n",
    "# \"\"\".strip().format(\n",
    "#         languge.lower(), question.strip()\n",
    "#     )\n",
    "\n",
    "def generate_one_completion(question, model, tokenizer, max_new_tokens=1024):\n",
    "    \"\"\"Generate a single completion for a given prompt\"\"\"\n",
    "    # prompt = build_qwen_instruction(question)\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "    \n",
    "    completion = tokenizer.decode(outputs[0][len(inputs[0]) :], skip_special_tokens=True)\n",
    "    # code = extract_generation_code(completion, lang_code='python', verbose=True)\n",
    "    return completion\n",
    "\n",
    "def main():\n",
    "    model_name = \"Qwen/Qwen2.5-Coder-7B\"  \n",
    "    print(f\"Loading {model_name}...\")\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"cuda\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    \n",
    "    problems = read_problems()\n",
    "    num_samples_per_task = 1  # Increase this for pass@k metrics\n",
    "    \n",
    "    print(f\"Generating {num_samples_per_task} samples per task...\")\n",
    "    samples = []\n",
    "    \n",
    "    for task_id in tqdm(problems.keys(), desc=\"Generating solutions\"):\n",
    "        for _ in range(num_samples_per_task):\n",
    "            try:\n",
    "                completion = generate_one_completion(problems[task_id][\"prompt\"], model, tokenizer)\n",
    "                samples.append({\n",
    "                    \"task_id\": task_id,\n",
    "                    \"completion\": completion\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError on task {task_id}: {str(e)}\")\n",
    "    \n",
    "    output_file = f\"samples_{model_name.replace('/', '_')}.json\"\n",
    "    write_jsonl(output_file, samples)\n",
    "    print(f\"Samples saved to {output_file}\")\n",
    "    print(\"\\nTo evaluate, run:\")\n",
    "    result = evaluate_functional_correctness(\n",
    "        sample_file=output_file,\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molm-s10SfoP9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
